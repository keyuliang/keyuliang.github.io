{"pages":[],"posts":[{"title":"绘制阴影原理","text":"Webgl 指南绘制步骤下图时webgl指南里面绘制阴影的主要步骤： 假设有这么一个场景 相机位置和光源位置的视角分别为(以下分别称相机视角、光源视角) 绘制过程第一步利用FBO（帧缓冲区对象）得到的在光源视角得到的深度信息。 比较简单，只是简单MVP变换，光栅化后把变换后的Z值写入R通道，由于三角形再正方形得前面，所以三角形范围的深度信息会覆盖正方形的深度信息。如果把第四个值改成1.0就可以得正方形和三角形得颜色都是红色（为了好理解），但是三角形偏暗一点，类似下图（假设值），可以改一下代码直接输出到颜色缓冲区看一下。 第二步回到相机视角正常渲染，分别计算相机视角的MVP变换（28行，这个是要显示到屏幕的）和光源视角的MVP变换（29行，这里的变换和第一步的变化是一样的），前者通过gl_Position传到的片元着色器，后者通过Varying。 到了片元着色器，因为webgl的x、y再[-1，1]，而图片的坐标在[0，1]，如下图，所以需要通过42行转换一下 下面通过一个片元来解释一下： 假设P点刚好在三角形阴影的直角点。P点在光源视角的MVP变换（29行）下在经过坐标转换（42行）可以得到O点的坐标未[Xo，Yo，Zo]。经过前面的变换后O点的[Xo,Yo]和E点的[Xe,Ye]是相等的，所以可以通过O点的[Xo,Yo]（43行）得到前面计算的E点的深度信息（44行，当时记录在了R通道）。假设P点在光源视角（O点）的深度值Zo = 0.7，而E点由于三角形在正方形的前面，深度信息记录的是三角形的深度值，假设是Ze = 0.5，由于Zo比Ze大，所以P点在阴影中（45行，至于为什么+0.05我也不清楚）。以此类推就可以算出那些片元在阴影中了。","link":"/2022/04/03/webgl%E7%BB%98%E5%88%B6%E9%98%B4%E5%BD%B1%E5%8E%9F%E7%90%86/"},{"title":"Three拾取原理","text":"射线拾取顾名思义，射线拾取就是从相机发射一条无限远的射线，然后判断射线和那些物体相交。如下图 官方案例下面直接来看Three官方文档的射线拾取代码，这段代码是每帧都会在相机发射一条到鼠标位置的射线并返回射线击中的物体，最后修改材质颜色。 12345678910111213141516171819const raycaster = new THREE.Raycaster();const mouse = new THREE.Vector2();function onMouseMove( event ) { // 将鼠标位置归一化为设备坐标。x 和 y 方向的取值范围是 (-1 to +1) mouse.x = ( event.clientX / window.innerWidth ) * 2 - 1; mouse.y = - ( event.clientY / window.innerHeight ) * 2 + 1;}function render() { // 通过摄像机和鼠标位置更新射线 raycaster.setFromCamera( mouse, camera ); // 计算物体和射线的焦点（这里的scene.children可以只传需要被射线检测的物体,不然物体太多会卡顿） const intersects = raycaster.intersectObjects( scene.children ); for ( let i = 0; i &lt; intersects.length; i ++ ) { intersects[ i ].object.material.color.set( 0xff0000 ); } renderer.render( scene, camera );}window.addEventListener( 'mousemove', onMouseMove, false );window.requestAnimationFrame(render); THREE射线拾取步骤 先把鼠标点击的（X,Y)从屏幕坐标系转成webgl坐标系。 然后再把webgl坐标系通过投影逆变换转成投影坐标系，得到（X,Y)在投影坐标系下的值(Xw,Yw,Zw)。 把(Xw,Yw,Zw)减去相机的坐标得到射线的方向向量（起点是相机的坐标，知道起点和方向就可以得到一条无限长的射线）。 射线先和检测物体的包围和求交。 把上一步检测相交的物体遍历每一个面，检测是否相交。 把相交的物体按照深度（Z）排序,并返回。 第1步，屏幕坐标系转webgl坐标系，具体计算方法。https://blog.csdn.net/u011332271/article/details/110477155 12mouse.x = ( event.clientX / window.innerWidth ) * 2 - 1;mouse.y = - ( event.clientY / window.innerHeight ) * 2 + 1; 第2、3步，计算射线的起点和方向。 1raycaster.setFromCamera( mouse, camera ); 可以查看raycaster.setFromCamera（）方法的代码，其中.unproject(camera)就是。 12345678910111213141516setFromCamera(coords, camera) { if (camera &amp;&amp; camera.isPerspectiveCamera) { // 起点设置为相机的位置 this.ray.origin.setFromMatrixPosition(camera.matrixWorld); // 屏幕坐标转成世界坐标，然后减去射线的起点就可以得到起点到点击的点的方向向量，最后归一化 this.ray.direction.set(coords.x, coords.y, 0.5).unproject(camera).sub(this.ray.origin).normalize(); this.camera = camera; } else if (camera &amp;&amp; camera.isOrthographicCamera) { this.ray.origin.set(coords.x, coords.y, (camera.near + camera.far) / (camera.near - camera.far)).unproject(camera); // set origin in plane of camera // 正交相机的没有近大远小，所以射线方向都是相机方向平行的 this.ray.direction.set(0, 0, -1).transformDirection(camera.matrixWorld); this.camera = camera; } else { console.error('THREE.Raycaster: Unsupported camera type.'); } }, 第4步，射线先和检测物体的包围和求交，先和包围体求交可以排除那先必定不相交的物体，减少后面的计算量。 1const intersects = raycaster.intersectObjects( scene.children ); 节选代码 12345678910111213// Checking boundingSphere distance to rayif (geometry.boundingSphere === null) geometry.computeBoundingSphere();_sphere.copy(geometry.boundingSphere);_sphere.applyMatrix4(matrixWorld);if (raycaster.ray.intersectsSphere(_sphere) === false) return;// 这里用射线乘模型矩阵得逆矩阵得到-ray相当于射线逆着模型变换，保证和模形的相对位置，后面检测射线和模型的面相交的情况的时候就可以直接用模型未经过变换的点来计算// 不然的话要先计算变换后的模型，在和ray(未变换的)进行相交检测，而且后面还需要和模型的面求交，每一个面都需要变换，计算量大_inverseMatrix.copy(matrixWorld).invert();_ray.copy(raycaster.ray).applyMatrix4(_inverseMatrix); // Check boundingBox before continuingif (geometry.boundingBox !== null) { if (_ray.intersectsBox(geometry.boundingBox) === false) return;} _ray的计算具体可以看下图，计算_ray可以不旋转模型就保持和模型的相对位置。 第5、6步，通过包围盒检测的模型继续遍历模型的面在判断相交（具体代码可以查看Mesh对象的raycast()方法，这里就不贴出），最后再把相交物体按照深度排序返回。 12intersects.sort(ascSort);return intersects; 以上就是THREE里射线拾取的原理的，可以看出当场景的模型数量大的时候，每一个模型都要检测一次的计算量是非常大的。但是这个也是有办法优化的，一个是通过八叉树把场景的模型管理起来，每一次只检测一小部分（这里先不展开），另外一个就是通过缓冲区拾取。 缓冲区拾取缓冲区拾取就是利用FBO(帧缓冲区)渲染另外一份顶点数据一样，但是顶点颜色是按照ID位计算成RGB值，这样就保证了每一个的物体的颜色之都不一样，这样点击的时候获取到点击位置的RGB值，再位换算回ID值就可以知道点击到那个物体了。其实说白了缓冲区拾取就是用空间（多一份数据）换时间（拾取快），另外由于缓冲区拾取不需要遍历模型，所以模型是可以做合批的。 THREE缓冲区拾取步骤 准备好两份数据，一份渲染输出到屏幕，一份渲染到FBO，同时把每个物体的信息存起来。 创建一个webglRenderTarget()(FBO，不直接输出到屏幕)。 渲染FBO，通过获取到的颜色位换算回ID值，判断点击了那个物体。 通过ID值获取到点击的物体的信息，在生成一个正方体套在点击物体外面，表示高亮。 最后正常渲染场景，输出到颜色缓冲区（屏幕）。 下面来一起看一下THREE的例子 webgl_interactive_cubes_gpu 第1步,准备两份数据。 12345678910111213141516171819202122232425262728293031323334353637383940for ( let i = 0; i &lt; 5000; i ++ ) { let geometry = new THREE.BoxBufferGeometry(); // 生成随机模型矩阵 const position = new THREE.Vector3(); position.x = Math.random() * 10000 - 5000; position.y = Math.random() * 6000 - 3000; position.z = Math.random() * 8000 - 4000; const rotation = new THREE.Euler(); rotation.x = Math.random() * 2 * Math.PI; rotation.y = Math.random() * 2 * Math.PI; rotation.z = Math.random() * 2 * Math.PI; const scale = new THREE.Vector3(); scale.x = Math.random() * 200 + 100; scale.y = Math.random() * 200 + 100; scale.z = Math.random() * 200 + 100; quaternion.setFromEuler( rotation ); matrix.compose( position, quaternion, scale ); geometry.applyMatrix4( matrix ); // 给BOX随机生成颜色 applyVertexColors( geometry, color.setHex( Math.random() * 0xffffff ) ); // push到数组。第一份数据准备完成 geometriesDrawn.push( geometry ); // 复制一份新的数据 geometry = geometry.clone(); // 通过i位换算设置颜色，这样每一个的颜色都是唯一的 applyVertexColors( geometry, color.setHex( i ) ); // push到数组，第二份数据准备完成 geometriesPicking.push( geometry ); // 保存每一个BOX的模型矩阵，后面用于生成HeightLightBox pickingData[ i ] = { position: position, rotation: rotation, scale: scale };}// 把两份数组都合批，加载到各自的场景scene.add( new THREE.Mesh( BufferGeometryUtils.mergeBufferGeometries( geometriesDrawn ), defaultMaterial ) );pickingScene.add( new THREE.Mesh( BufferGeometryUtils.mergeBufferGeometries( geometriesPicking ), pickingMaterial ) ); 第2、3、4、5步 1pickingTexture = new THREE.WebGLRenderTarget( 1, 1 ); 这里设置为（1，1）是因为只需要拿一个像素的颜色值就行了，设大了反而增加计算量。 123456789101112131415161718192021222324252627282930function pick() { // 渲染FBO( pickingTexture) // 将视图偏移设置为仅代表鼠标下方的单个像素 camera.setViewOffset( renderer.domElement.width, renderer.domElement.height, mouse.x * window.devicePixelRatio | 0, mouse.y * window.devicePixelRatio | 0, 1, 1 ); // 渲染pickingTexture renderer.setRenderTarget( pickingTexture ); renderer.render( pickingScene, camera ); // 把相机恢复到正常状态 camera.clearViewOffset(); const pixelBuffer = new Uint8Array( 4 ); // 获取pickingTexture的颜色值 renderer.readRenderTargetPixels( pickingTexture, 0, 0, 1, 1, pixelBuffer ); // 位换算回ID值 const id = ( pixelBuffer[ 0 ] &lt;&lt; 16 ) | ( pixelBuffer[ 1 ] &lt;&lt; 8 ) | ( pixelBuffer[ 2 ] ); // 获取到点击的物体的矩阵信息 const data = pickingData[ id ]; if ( data ) { // 把highlightBox变换到对应的位置 if ( data.position &amp;&amp; data.rotation &amp;&amp; data.scale ) { highlightBox.position.copy( data.position ); highlightBox.rotation.copy( data.rotation ); highlightBox.scale.copy( data.scale ).add( offset ); highlightBox.visible = true; } } // 否则就是没选中，隐藏hignlightBox else { highlightBox.visible = false; }} 上面代码大概就是缓冲区拾取的原理，当然不一定是要生成highlightBox来表示高亮，也可以去修改对应geometry里面的VertexColors。 12345678function render() { controls.update(); // 渲染FBO并获取到鼠标点击到的物体 pick(); // 切换回颜色缓冲区，正常渲染输出到屏幕 renderer.setRenderTarget( null ); renderer.render( scene, camera );} 切换回颜色缓冲区，正常渲染输出到屏幕 射线拾取和缓冲区拾取优缺点通过上面的解释我们不难看出，射线拾取可以拿到所有被射线击中的物体，并且可以拿到击中了模型具体的哪一个面和UV等信息。这些信息在一个射击游戏里面就显得很重要了，比如击中墙后面的人、在墙上留下弹孔等等。缺点就是场景物体多了就行卡，而且不能合批模型。相反，缓冲区拾取就是模型多也不会拾取卡，但是就拿不到详细的信息了，所以缓冲区拾取就比较适用在BIM模型的拾取上。 好了，上面就是作者对THREE射线拾取和缓冲区拾取的理解了，有哪些不对的地方希望各有可以指出。","link":"/2022/04/02/Three%E6%8B%BE%E5%8F%96%E5%8E%9F%E7%90%86/"},{"title":"法线贴图原理","text":"1.法线贴图在计算 phong 渲染模型的时候有一步是计算光照方向和法线方向的夹角，以计算光照强度，比如下面的代码。 12float DotN = dot(normal, lightDir);vec3 finalColor = baseColor * Dotn; 所以当法线越多且方向不同的时候（顶点和三角面越多）会渲染出更多的细节，比如左图。但是顶点过多导致内存占用大，计算量大等问题，减少顶点三角面的话又会导致失去这些细节。但是还有一种方法可以使得在使用较少的顶点三角面的同时保留这些光照细节，这个方法就是使用法线贴图，比如右图。 法线贴图的原理法线贴图一般长下面这样,它的基本原理是使用图片的 R、G、B 值去存储模型的法线的 X、Y、Z。在计算光照的时候再根据 UV 去采样图片的 RGB 值，然后归一化成法线。 和上面的代码相比，下面的代码就是把原本顶点法线插值出来的法线值用了法线贴图采样的法线值代替了,这时候就会得到一个基本的效果了。 123Vec3 texNormal = noramlize(texture2D(noramlTexture, uv)) * 2 - 1;float DotN = dot(texNormal, lightDir);vec3 finalColor = baseColor * Dotn; 上面的结果看起来是正确的，但是如果你把平面换成正方体，仔细观察就会发现蓝色边框的阴影是正确的，但是红色边框的阴影似乎是由绿色箭头方向的光产生的。 为什么会产生这种现象呢？上面我们说过法线贴图的 RGB 存储了法线的 XYZ，在计算蓝色边框的面的时候从法线贴图采样到的法线刚好是垂直该面的，但红色边框的面采样到的值是确实平行该面，计算得到阴影也就不正确了。 当然，我们可以把模型的 UV 展开，然后在法线贴图里面准确记录每一个面的法线。另外还有一个好的解决办法就是切线空间。 切线空间切线空间可以理解为 Z 轴永远垂直于三角面，X 和 Y 轴和三角面处于同于平面，三者互相垂直，X、Y、Z 分别对应着 T (tangent切线)、B（bitangent副切线）、N（normal法线）, 比如下图 可以看到蓝色边框的面因为切线空间坐标和世界空间切线空间坐标刚好相同，所以该面的光照计算没有错误。 那么只要我们可以把世界空间坐标都转换到切线空间坐标（或者相反）那就算光照不就正确了。这时候就需要一个变换矩阵，这个矩阵就是 TBN 矩阵。 可以看到如果要求出这个矩阵就要分别求出 T、B、N。N 我们是知道，就是三角面的法线。T、B 虽然和三角面在同一个平面上，但是还是有无数的方向。由于T、B、N是互相垂直的，所以T、B只有求出其中一个，另外一个和 N 叉乘就可以得到，一般计算 T。具体的计算方法可以参考这篇[文章](https://learnopengl-cn.github.io/05%20Advanced%20Lighting/04%20Normal%20Mapping/#_1),这里不展开（主要是我自己没去算哈哈哈）。当然，切线 T 可以在三维软件导出模型的时候顺便算出 T 保存在数据中，比如在 blender 可以勾选 又或者3D引擎算出 T 比如在 three 中： 12const geometry = new THREE.BoxGeometry( 20, 20, 20 ); geometry.computeTangents() 计算光照有了 TBN 变换矩阵之后就可以世界空间的坐标变换到切线空间，或者相反。那么这里就会有两种方法计算光照，一是把采样得到的切线空间的法线变换到世界空间，然后在和世界空间的光照方向计算。第二种是直接用 TBN 矩阵的逆矩阵把世界光照方向变换到切线空间中，这样计算出来的结果也是正确的。但是第二种的性能明显是会比第一种好的，第一种需要在片元着色器把每次采样出来的法向都左乘 TBN 矩阵变换到世界空间。 1234567 //顶点着色器vTBN = mat3(vt, vb, normalize(TranfromNormal)); //片元着色器vec3 texN = normalize(texture2D(uNormalTex, vUv).xyz * 2.0 - 1.0);;vec3 worldNormal = normalize( vTBN * texN ); float nDotL = max(0.0, dot(worldNormal, vlightDirection)); 但是第二种的话我们只需要在顶点着色器把世家空间的光照左乘 TBN 的逆矩阵，变换到切线空间，在把切线空间的光照用 varying 传给片元着色器即可。一般来说顶点着色器的计算会比片元着色器少得多。 123456789 //顶点着色器vTBN = mat3(vt, vb, normalize(TranfromNormal)); //因为TBN矩阵为正交矩阵，正交矩阵的转置和逆矩阵相同，同时转置的计算会比逆矩阵简单vTBN = transposeMat3(vTBN);vlightDirection = normalize( vTBN * vLightPosition); //片元着色器 vec3 texN = normalize(texture2D(uNormalTex, vUv).xyz * 2.0 - 1.0);;float nDotL = max(0.0, dot(texN, vlightDirection)); 最后看看在 three 实现的效果。","link":"/2022/05/04/%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"图形学","slug":"图形学","link":"/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"THREE","slug":"THREE","link":"/tags/THREE/"}],"categories":[{"name":"原理研究","slug":"原理研究","link":"/categories/%E5%8E%9F%E7%90%86%E7%A0%94%E7%A9%B6/"}]}